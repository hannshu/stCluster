{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and load model parameters by stCluster\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In certain scenarios, users may find it necessary to retain the embeddings or model parameters acquired during training for subsequent training sessions or to ensure reproducibility in other hardwares. The stCluster framework offers a method that enables users to efficiently and promptly save and load model parameters. The following tutorial will utilize the ZESTA dataset to illustrate this process.  \n",
    "\n",
    "Frist, we load the dataset, train latent representation by stCluster and save the model parameters and embedding matrix by setting attribute `save_model` and `save_embedding` in function `stCluster.train.train()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> INFO: Download dataset: 100%|██████████| 234M/234M [04:01<00:00, 1.01MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> INFO: dataset name: zebrafish embryogenesis spatiotemporal transcriptomic atlas (ZESTA), size: (13166, 26628), cluster: 45.(242.497s)\n",
      ">>> INFO: Input size torch.Size([13166, 3000]).\n",
      ">>> INFO: Graph contains 41704 edges, average 3.168 edges per node.\n",
      ">>> INFO: Build graph success!\n",
      ">>> INFO: Finish generate precluster embedding!\n",
      ">>> INFO: Finish pre-cluster, result image is saved at \"None\", begin to prune graph.\n",
      ">>> INFO: Finish pruning graph, result image is saved at \"None\".\n",
      ">>> INFO: Graph contains 367103 edges, average 27.883 edges per node.\n",
      ">>> INFO: Build graph success!\n",
      ">>> INFO: Finish model preparations, begin to train model, input data size: (13166, 3000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> INFO: Training: 100%|██████████| 1000/1000 [01:13<00:00, 13.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> INFO: Successfully save embedding at zesta_embedding.npy.\n",
      ">>> INFO: Successfully export model at zesta_model.pkl.\n",
      ">>> INFO: Finish embedding process, total time: 144.739s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from st_datasets.dataset import get_data, get_zesta_data\n",
    "from stCluster.train import train\n",
    "\n",
    "adata, n_cluster = get_data(get_zesta_data)\n",
    "_ = train(adata, radius=15, save_model='zesta_model.pkl', save_embedding='zesta_embedding.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model parameters\n",
    "We can easily load the model parameters in another device, generate embedding again and do downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> INFO: Use locate data.\n",
      ">>> INFO: dataset name: zebrafish embryogenesis spatiotemporal transcriptomic atlas (ZESTA), size: (13166, 26628), cluster: 45.(0.424s)\n",
      ">>> INFO: Input size torch.Size([13166, 3000]).\n",
      ">>> INFO: Graph contains 41704 edges, average 3.168 edges per node.\n",
      ">>> INFO: Build graph success!\n",
      ">>> INFO: Finish load model, begin to generate embedding and rebuild gene expression, input data size: (13166, 3000).\n",
      ">>> INFO: Finish embedding generation process, please use the embedding to do downstream evaluation, total time: 0.340s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]:                    __           __ \n",
      "   ____ ___  _____/ /_  _______/ /_\n",
      "  / __ `__ \\/ ___/ / / / / ___/ __/\n",
      " / / / / / / /__/ / /_/ (__  ) /_  \n",
      "/_/ /_/ /_/\\___/_/\\__,_/____/\\__/   version 5.4.10\n",
      "Type 'citation(\"mclust\")' for citing this R package in publications.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting ...\n",
      "  |======================================================================| 100%\n",
      "{'mclust': 0.35190349034463836}\n"
     ]
    }
   ],
   "source": [
    "from st_datasets.dataset import get_data, get_zesta_data\n",
    "from stCluster.run import load_and_evaluate\n",
    "\n",
    "adata, n_cluster = get_data(get_zesta_data)\n",
    "adata, score = load_and_evaluate(adata, radius=15, n_cluster=n_cluster, cluster_method='mclust', cluster_score_method='ARI', model_paras_path='zesta_model.pkl')\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model parameters obtained through training with stCluster can be acquired from the containers we have provided at the following locations: `\\root\\stCluster_paras`. Utilizing the aforementioned resources, you can readily and expeditiously generate latent representation in your device and do downstream analytical tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stCluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
